{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1, ConfusionMatrix\n",
    "import torchvision.models as models\n",
    "\n",
    "from tools.utils import create_dir\n",
    "from dataset import get_dataset\n",
    "from model import get_model\n",
    "from tools.checkpoint import CheckpointManager, Checkpoint\n",
    "from tools.train_manager import TrainManager\n",
    "from one_stage.new_dataset import SpectrogramDataset\n",
    "from dataset import create_data_loader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "train_dataset = SpectrogramDataset(\n",
    "    \"/home/dev/dataset/onc/preprocessed/train\", \"mel\", [\"other\"]\n",
    ")\n",
    "validation_dataset = SpectrogramDataset(\n",
    "    \"/home/dev/dataset/onc/preprocessed/validation\", \"mel\", [\"other\"]\n",
    ")\n",
    "\n",
    "train_dataloader = create_data_loader(train_dataset, batch_size)\n",
    "validation_dataloader = create_data_loader(validation_dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, labels in train_dataloader:\n",
    "    print(\"Input shape:\", inputs.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchsummary import summary\n",
    "\n",
    "# Define the number of classes and input channels\n",
    "num_of_classes = 5\n",
    "input_channels = 3\n",
    "\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "# Modify the first layer to accept single-channel input\n",
    "vgg16.features[0] = nn.Conv2d(\n",
    "    input_channels, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
    ")\n",
    "\n",
    "# Modify the last layer to output 5 classes\n",
    "vgg16.classifier[6] = nn.Linear(4096, num_of_classes)\n",
    "\n",
    "for param in vgg16.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Print the modified VGG16 architecture\n",
    "model = vgg16.to(\"cuda\")\n",
    "print(\"Model Architecture\")\n",
    "print(summary(model, (input_channels, 95, 126)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(vgg16.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "model.train()\n",
    "device = \"cuda\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for inputs, labels in tqdm(\n",
    "        train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False\n",
    "    ):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_accuracy = correct_predictions / total_samples\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "model.eval()\n",
    "val_correct_predictions = 0\n",
    "val_total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(validation_dataloader, desc=\"Validation\", leave=False):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        val_correct_predictions += (predicted == labels).sum().item()\n",
    "        val_total_samples += labels.size(0)\n",
    "\n",
    "val_accuracy = val_correct_predictions / val_total_samples\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper VGGNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 16, 97, 128]             160\n",
      "       BatchNorm2d-2          [-1, 16, 97, 128]              32\n",
      "         LeakyReLU-3          [-1, 16, 97, 128]               0\n",
      "         MaxPool2d-4           [-1, 16, 48, 64]               0\n",
      "            Conv2d-5           [-1, 32, 50, 66]           4,640\n",
      "       BatchNorm2d-6           [-1, 32, 50, 66]              64\n",
      "         LeakyReLU-7           [-1, 32, 50, 66]               0\n",
      "         MaxPool2d-8           [-1, 32, 25, 33]               0\n",
      "            Conv2d-9           [-1, 64, 27, 35]          18,496\n",
      "      BatchNorm2d-10           [-1, 64, 27, 35]             128\n",
      "        LeakyReLU-11           [-1, 64, 27, 35]               0\n",
      "        MaxPool2d-12           [-1, 64, 13, 17]               0\n",
      "           Conv2d-13          [-1, 128, 15, 19]          73,856\n",
      "      BatchNorm2d-14          [-1, 128, 15, 19]             256\n",
      "        LeakyReLU-15          [-1, 128, 15, 19]               0\n",
      "        MaxPool2d-16            [-1, 128, 7, 9]               0\n",
      "          Flatten-17                 [-1, 8064]               0\n",
      "           Linear-18                    [-1, 5]          40,325\n",
      "          Softmax-19                    [-1, 5]               0\n",
      "================================================================\n",
      "Total params: 137,957\n",
      "Trainable params: 137,957\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 9.99\n",
      "Params size (MB): 0.53\n",
      "Estimated Total Size (MB): 10.56\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_channels=1, num_classes=5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=input_channels,\n",
    "                out_channels=16,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(128 * 7 * 9, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        x = self.conv1(input_data)\n",
    "        # print(\"Shape after conv1:\", x.shape)\n",
    "        x = self.conv2(x)\n",
    "        # print(\"Shape after conv2:\", x.shape)\n",
    "        x = self.conv3(x)\n",
    "        # print(\"Shape after conv3:\", x.shape)\n",
    "        x = self.conv4(x)\n",
    "        # print(\"Shape after conv4:\", x.shape)\n",
    "        x = self.flatten(x)\n",
    "        # print(\"Shape after flattening:\", x.shape)\n",
    "        # print(\"Shape of the weight matrix:\", self.linear.weight.shape)\n",
    "        logits = self.linear(x)\n",
    "        predictions = self.softmax(logits)\n",
    "        return predictions\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model = CNN()\n",
    "input_channels = 1\n",
    "\n",
    "model = model.to(\"cuda\")\n",
    "print(\"Model Architecture\")\n",
    "print(summary(model, (input_channels, 95, 126)))\n",
    "\n",
    "# Print the model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper ResNet18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n",
      "Model Architecture\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 48, 63]           3,136\n",
      "       BatchNorm2d-2           [-1, 64, 48, 63]             128\n",
      "              ReLU-3           [-1, 64, 48, 63]               0\n",
      "         MaxPool2d-4           [-1, 64, 24, 32]               0\n",
      "            Conv2d-5           [-1, 64, 24, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 24, 32]             128\n",
      "              ReLU-7           [-1, 64, 24, 32]               0\n",
      "            Conv2d-8           [-1, 64, 24, 32]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 24, 32]             128\n",
      "             ReLU-10           [-1, 64, 24, 32]               0\n",
      "       BasicBlock-11           [-1, 64, 24, 32]               0\n",
      "           Conv2d-12           [-1, 64, 24, 32]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 24, 32]             128\n",
      "             ReLU-14           [-1, 64, 24, 32]               0\n",
      "           Conv2d-15           [-1, 64, 24, 32]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 24, 32]             128\n",
      "             ReLU-17           [-1, 64, 24, 32]               0\n",
      "       BasicBlock-18           [-1, 64, 24, 32]               0\n",
      "           Conv2d-19          [-1, 128, 12, 16]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 12, 16]             256\n",
      "             ReLU-21          [-1, 128, 12, 16]               0\n",
      "           Conv2d-22          [-1, 128, 12, 16]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 12, 16]             256\n",
      "           Conv2d-24          [-1, 128, 12, 16]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 12, 16]             256\n",
      "             ReLU-26          [-1, 128, 12, 16]               0\n",
      "       BasicBlock-27          [-1, 128, 12, 16]               0\n",
      "           Conv2d-28          [-1, 128, 12, 16]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 12, 16]             256\n",
      "             ReLU-30          [-1, 128, 12, 16]               0\n",
      "           Conv2d-31          [-1, 128, 12, 16]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 12, 16]             256\n",
      "             ReLU-33          [-1, 128, 12, 16]               0\n",
      "       BasicBlock-34          [-1, 128, 12, 16]               0\n",
      "           Conv2d-35            [-1, 256, 6, 8]         294,912\n",
      "      BatchNorm2d-36            [-1, 256, 6, 8]             512\n",
      "             ReLU-37            [-1, 256, 6, 8]               0\n",
      "           Conv2d-38            [-1, 256, 6, 8]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 6, 8]             512\n",
      "           Conv2d-40            [-1, 256, 6, 8]          32,768\n",
      "      BatchNorm2d-41            [-1, 256, 6, 8]             512\n",
      "             ReLU-42            [-1, 256, 6, 8]               0\n",
      "       BasicBlock-43            [-1, 256, 6, 8]               0\n",
      "           Conv2d-44            [-1, 256, 6, 8]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 6, 8]             512\n",
      "             ReLU-46            [-1, 256, 6, 8]               0\n",
      "           Conv2d-47            [-1, 256, 6, 8]         589,824\n",
      "      BatchNorm2d-48            [-1, 256, 6, 8]             512\n",
      "             ReLU-49            [-1, 256, 6, 8]               0\n",
      "       BasicBlock-50            [-1, 256, 6, 8]               0\n",
      "           Conv2d-51            [-1, 512, 3, 4]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 3, 4]           1,024\n",
      "             ReLU-53            [-1, 512, 3, 4]               0\n",
      "           Conv2d-54            [-1, 512, 3, 4]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 3, 4]           1,024\n",
      "           Conv2d-56            [-1, 512, 3, 4]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 3, 4]           1,024\n",
      "             ReLU-58            [-1, 512, 3, 4]               0\n",
      "       BasicBlock-59            [-1, 512, 3, 4]               0\n",
      "           Conv2d-60            [-1, 512, 3, 4]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 3, 4]           1,024\n",
      "             ReLU-62            [-1, 512, 3, 4]               0\n",
      "           Conv2d-63            [-1, 512, 3, 4]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 3, 4]           1,024\n",
      "             ReLU-65            [-1, 512, 3, 4]               0\n",
      "       BasicBlock-66            [-1, 512, 3, 4]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                    [-1, 5]           2,565\n",
      "           ResNet-69                    [-1, 5]               0\n",
      "================================================================\n",
      "Total params: 11,172,805\n",
      "Trainable params: 11,172,805\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 15.31\n",
      "Params size (MB): 42.62\n",
      "Estimated Total Size (MB): 57.98\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define a custom ResNet-18 model\n",
    "class CustomResNet18(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomResNet18, self).__init__()\n",
    "        # Load the pre-trained ResNet-18 model\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "\n",
    "        # Modify the first convolutional layer to accept 1 input channel\n",
    "        # Original input channels: 3\n",
    "        # New input channels: 1\n",
    "        resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        # Modify the output layer to have the desired number of classes\n",
    "        num_ftrs = resnet.fc.in_features\n",
    "        resnet.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "        self.resnet = resnet\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model = CustomResNet18(num_classes=5)\n",
    "\n",
    "# Test the model with random input\n",
    "input_tensor = torch.randn(1, 1, 95, 126)  # Batch size, channels, height, width\n",
    "output = model(input_tensor)\n",
    "print(output.shape)\n",
    "\n",
    "input_channels = 1\n",
    "model = model.to(\"cuda\")\n",
    "print(\"Model Architecture\")\n",
    "print(summary(model, (input_channels, 95, 126)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
